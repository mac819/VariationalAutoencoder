{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a14c3f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-Dataset\" data-toc-modified-id=\"Loading-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading Dataset</a></span></li><li><span><a href=\"#Reading-TFRecord-Data\" data-toc-modified-id=\"Reading-TFRecord-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reading TFRecord Data</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1e4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304cca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "\n",
    "from gans.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306cd0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.5.0\n",
      "Pandas Version: 1.3.3\n",
      "Numpy Version: 1.19.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca27097c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mayankanand/Documents/GANs/data/monet_tfrec\n",
      "/Users/mayankanand/Documents/GANs/data/photo_tfrec\n"
     ]
    }
   ],
   "source": [
    "print(MONET_TFREC_PATH)\n",
    "print(PHOTO_TFREC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72aa4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = MONET_TFREC_PATH + \"/*.tfrec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a6efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "monet_file_path = glob.glob(MONET_TFREC_PATH + \"/*.tfrec\")\n",
    "photo_file_path = glob.glob(PHOTO_TFREC_PATH + \"/*.tfrec\")\n",
    "print(len(monet_file_path))\n",
    "print(len(photo_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8fe35",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ca233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-03 21:18:45.334771: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-10-03 21:18:45.335726: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "photo_dataset = tf.data.TFRecordDataset(photo_file_path)\n",
    "monet_dataset = tf.data.TFRecordDataset(monet_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215308c3",
   "metadata": {},
   "source": [
    "# Reading TFRecord Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e711a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    return tf.image.decode_jpeg(example['image'], channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea1bf33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_monet_dataset = monet_dataset.map(read_tfrecord)\n",
    "parsed_photo_dataset = photo_dataset.map(read_tfrecord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ad899",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65ce0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input\n",
    "from gans.model import encoder, \\\n",
    "                        sampling, \\\n",
    "                        sampling_reparameterization, \\\n",
    "                        decoder, \\\n",
    "                        kl_loss, \\\n",
    "                        mse_loss, \\\n",
    "                        vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2ac776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_DEPTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eeefffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = encoder((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3d5b869",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_encoder (InputLayer)      [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 256, 256, 32) 896         input_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 256, 256, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lrelu_1 (LeakyReLU)             (None, 256, 256, 32) 0           bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 128, 128, 64) 18496       lrelu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_2 (BatchNormalization)       (None, 128, 128, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lrelu_2 (LeakyReLU)             (None, 128, 128, 64) 0           bn_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 64, 64, 64)   36928       lrelu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_3 (BatchNormalization)       (None, 64, 64, 64)   256         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lrelu_3 (LeakyReLU)             (None, 64, 64, 64)   0           bn_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 64, 64, 64)   36928       lrelu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_4 (BatchNormalization)       (None, 64, 64, 64)   256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lrelu_4 (LeakyReLU)             (None, 64, 64, 64)   0           bn_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 262144)       0           lrelu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mean (Dense)                    (None, 2)            524290      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 2)            524290      flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,142,724\n",
      "Trainable params: 1,142,276\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7718db23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       " array([[-0.15481597,  0.05505916],\n",
       "        [-0.19965369,  0.17421967],\n",
       "        [-0.16472606,  0.12418295],\n",
       "        [-0.03628612,  0.23116367]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       " array([[ 0.1602972 ,  0.03126954],\n",
       "        [-0.319545  , -0.11586682],\n",
       "        [ 0.07846078, -0.04879358],\n",
       "        [-0.03864841, -0.08212896]], dtype=float32)>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model(tf.random.normal(shape=(4, 256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b52952ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, log_var = encoder_model(tf.random.normal(shape=(4, 256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ae29abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 2], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68ff0628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[ 0.04896349, -0.51314664],\n",
       "       [ 0.6910113 ,  0.18406335],\n",
       "       [ 0.7042561 , -1.2134677 ],\n",
       "       [-1.553101  ,  0.2302717 ]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=tf.shape(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "042f2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'tf.random.normal_5')>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=tf.shape(Input(shape=2, name=\"test_layer_1\")), mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5092b6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[-0.13945223,  0.27777633],\n",
       "       [-0.8120544 ,  0.1620354 ],\n",
       "       [-2.46675   ,  2.0823932 ],\n",
       "       [-0.11460114, -0.26638553]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(4, 2), mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c217e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0041661>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(tf.constant(1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ab68045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(input_1, input_2):\n",
    "    mean = Input(shape=input_1, name=\"input_layer1\")\n",
    "    log_var = Input(shape=input_2, name=\"input_layer2\")\n",
    "\n",
    "    out = layers.Lambda(sampling_reparameterization, name=\"encoder_output\")([mean, log_var])\n",
    "    enc_2 = keras.Model([mean, log_var], out, name=\"Encoder_2\")\n",
    "\n",
    "    return enc_2\n",
    "\n",
    "def sampling_reparameterization(distribution_params):\n",
    "    mean, log_var = distribution_params\n",
    "    epsilon = tf.random.normal(shape=tf.shape(mean), mean=0., stddev=1.)\n",
    "    z = mean + tf.exp(log_var / 2) * epsilon\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0b0f83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x287574dc0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5e1c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(16, 256, 256, 3)\n",
      "(12, 256, 256, 3)\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for data in parsed_monet_dataset.batch(16):\n",
    "    print(data.shape)\n",
    "    count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a62b735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "mean, log_var = encoder([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])(data)\n",
    "\n",
    "# Sampling Layer\n",
    "latent_vec = sampling(2, 2)([mean, log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e8ee9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "image = decoder(2)(latent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in parsed_monet_dataset.batch(16):\n",
    "    \n",
    "    # Encoder\n",
    "    mean, log_var = encoder([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])(data)\n",
    "\n",
    "    # Sampling Layer\n",
    "    latent_vec = sampling(2, 2)([mean, log_var])\n",
    "    \n",
    "    # Deocder\n",
    "    \n",
    "    \n",
    "    # Loss Function\n",
    "    \n",
    "    # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04614592",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, log_var = encoder([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc97730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1 = np.random.uniform(size=(32, 32, 3))\n",
    "arr_2 = np.random.uniform(size=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7cc20375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(arr_1 - arr_2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c7ddf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = decoder(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2cc50370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "Reshape_Layer (Reshape)      (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_transpose_1 (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "lrelu_1 (LeakyReLU)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_transpose_2 (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "lrelu_2 (LeakyReLU)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_transpose_3 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "bn_3 (BatchNormalization)    (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "lrelu_3 (LeakyReLU)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_transpose_4 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 102,657\n",
      "Trainable params: 102,337\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "90280f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6debdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da59463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(UpSampling2D(size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d7acfdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(1, 2, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f8bb6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_5 (UpSampling2 (1, 4, 4, 1)              0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e4de5608",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_img = tf.random.normal(shape=(1, 2, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85670268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a71bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087c9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b2ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
